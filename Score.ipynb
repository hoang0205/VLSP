{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14095803,"sourceType":"datasetVersion","datasetId":8976326},{"sourceId":684163,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":519118,"modelId":533591},{"sourceId":684169,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":519124,"modelId":533596}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets evaluate sacrebleu accelerate bitsandbytes peft nltk pandas\n\nimport nltk\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('omw-1.4')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T17:53:28.420866Z","iopub.execute_input":"2025-12-14T17:53:28.421071Z","iopub.status.idle":"2025-12-14T17:54:50.014591Z","shell.execute_reply.started":"2025-12-14T17:53:28.421032Z","shell.execute_reply":"2025-12-14T17:54:50.013814Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom peft import PeftModel\nimport evaluate\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nimport numpy as np\n\nbase_path = \"/kaggle/input/vlsp-dataset\" \n\npath_model_en_vi = \"/kaggle/input/nllb-eng-to-vie/pytorch/default/1/export_model_eng_to_vie\" \npath_model_vi_en = \"/kaggle/input/nllb-vie-to-eng/pytorch/default/1/export_model_vie_to_eng\"\n\nbase_checkpoint = \"facebook/nllb-200-distilled-600M\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmetric_bleu = evaluate.load(\"sacrebleu\")\nmetric_ter = evaluate.load(\"ter\")\nmetric_meteor = evaluate.load(\"meteor\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T17:54:50.015435Z","iopub.execute_input":"2025-12-14T17:54:50.015861Z","iopub.status.idle":"2025-12-14T17:55:25.204066Z","shell.execute_reply.started":"2025-12-14T17:54:50.015841Z","shell.execute_reply":"2025-12-14T17:55:25.203103Z"}},"outputs":[{"name":"stderr","text":"2025-12-14 17:55:03.157344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765734903.337770      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765734903.392349      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2fed8acb550416d8745b38f3ccae7e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"809dd11a67bf46ca8657226380ceb42f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"605790ee097d4d538c1bf50fd9e7fe28"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def run_evaluation(adapter_path, src_lang_code, tgt_lang_code, test_file_src, test_file_tgt, output_name):\n    print(f\"\\n{'='*10} REVIEWING: {src_lang_code} -> {tgt_lang_code} {'='*10}\")\n    \n    print(\"1.Loading model...\")\n    tokenizer = AutoTokenizer.from_pretrained(base_checkpoint, src_lang=src_lang_code)\n    base_model = AutoModelForSeq2SeqLM.from_pretrained(base_checkpoint)\n    \n    try:\n        model = PeftModel.from_pretrained(base_model, adapter_path)\n    except Exception as e:\n        print(f\"Error at {adapter_path}: {e}\")\n        return\n        \n    model.to(device)\n    model.eval()\n    \n    print(\"2. Reading test...\")\n    with open(test_file_src, 'r', encoding='utf-8') as f:\n        src_texts = f.read().splitlines()\n    with open(test_file_tgt, 'r', encoding='utf-8') as f:\n        ref_texts = f.read().splitlines()\n\n    print(f\"3. Translating... {len(src_texts)} câu...\")\n    predictions = []\n    tgt_lang_id = tokenizer.convert_tokens_to_ids(tgt_lang_code)\n    \n    batch_size = 16\n    for i in tqdm(range(0, len(src_texts), batch_size)):\n        batch_src = src_texts[i : i + batch_size]\n        \n        inputs = tokenizer(batch_src, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n        \n        with torch.no_grad():\n            generated_tokens = model.generate(\n                **inputs,\n                forced_bos_token_id=tgt_lang_id,\n                max_length=128,\n                num_beams=5, \n                early_stopping=True\n            )\n        \n        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n        predictions.extend([d.strip() for d in decoded])\n\n    print(\"4. Score...\")\n    bleu_refs = [[r] for r in ref_texts]\n    \n    score_bleu = metric_bleu.compute(predictions=predictions, references=bleu_refs)\n    score_ter = metric_ter.compute(predictions=predictions, references=ref_texts)\n    score_meteor = metric_meteor.compute(predictions=predictions, references=ref_texts)\n    \n    print(f\"\\n>>> RESULT: {src_lang_code}->{tgt_lang_code}:\")\n    print(f\"   BLEU  : {score_bleu['score']:.2f}\")\n    print(f\"   TER   : {score_ter['score']:.2f}\")\n    print(f\"   METEOR: {score_meteor['meteor']:.4f}\")\n    \n    print(\"5. Saving file...\")\n    df = pd.DataFrame({\n        \"Source\": src_texts,\n        \"Reference\": ref_texts,\n        \"Prediction\": predictions\n    })\n    \n    df[\"Sentence_BLEU\"] = [metric_bleu.compute(predictions=[p], references=[[r]])['score'] for p, r in zip(predictions, ref_texts)]\n    \n    csv_filename = f\"Analysis_{output_name}.csv\"\n    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n    print(f\"   File saved: {csv_filename}\")\n    \n    del model\n    del base_model\n    torch.cuda.empty_cache()\n    print(\"-\" * 40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T17:55:25.205465Z","iopub.execute_input":"2025-12-14T17:55:25.206103Z","iopub.status.idle":"2025-12-14T17:55:25.217117Z","shell.execute_reply.started":"2025-12-14T17:55:25.206079Z","shell.execute_reply":"2025-12-14T17:55:25.216230Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"run_evaluation(\n    adapter_path=path_model_en_vi,    \n    src_lang_code=\"eng_Latn\",\n    tgt_lang_code=\"vie_Latn\",\n    test_file_src=os.path.join(base_path, \"public_test.en.txt\"),\n    test_file_tgt=os.path.join(base_path, \"public_test.vi.txt\"),\n    output_name=\"En_Vi\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T17:55:25.219063Z","iopub.execute_input":"2025-12-14T17:55:25.219343Z","iopub.status.idle":"2025-12-14T18:17:35.884073Z","shell.execute_reply.started":"2025-12-14T17:55:25.219323Z","shell.execute_reply":"2025-12-14T18:17:35.883267Z"}},"outputs":[{"name":"stdout","text":"\n========== REVIEWING: eng_Latn -> vie_Latn ==========\n1.Loading model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a2d2435f9f64a56ab56365b915170e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eddd05c991f4de5a6fc46cbcf2aec78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c489840448640eb803cef9f9711c2e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c70418fccd614c01a99a7231855a02de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c21a1274d4943f1abdaca562461a0cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a74e47cf6d2f4489a21ddb0de7baa81f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72688c4f916d4377b7cd0c17a1cdd11e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60b9bd3ae4b444228bc71301e22ee0f2"}},"metadata":{}},{"name":"stdout","text":"2. Reading test...\n3. Translating... 3000 câu...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 188/188 [20:45<00:00,  6.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"4. Score...\n\n>>> RESULT: eng_Latn->vie_Latn:\n   BLEU  : 38.45\n   TER   : 53.25\n   METEOR: 0.6424\n5. Saving file...\n   File saved: Analysis_En_Vi.csv\n----------------------------------------\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"run_evaluation(\n    adapter_path=path_model_vi_en,    \n    src_lang_code=\"vie_Latn\",\n    tgt_lang_code=\"eng_Latn\",\n    test_file_src=os.path.join(base_path, \"public_test.vi.txt\"), \n    test_file_tgt=os.path.join(base_path, \"public_test.en.txt\"), \n    output_name=\"Vi_En\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:17:35.889249Z","iopub.execute_input":"2025-12-14T18:17:35.889560Z","iopub.status.idle":"2025-12-14T18:38:18.510928Z","shell.execute_reply.started":"2025-12-14T18:17:35.889539Z","shell.execute_reply":"2025-12-14T18:38:18.510029Z"}},"outputs":[{"name":"stdout","text":"\n========== REVIEWING: vie_Latn -> eng_Latn ==========\n1.Loading model...\n2. Reading test...\n3. Translating... 3000 câu...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 188/188 [20:01<00:00,  6.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"4. Score...\n\n>>> RESULT: vie_Latn->eng_Latn:\n   BLEU  : 31.34\n   TER   : 63.50\n   METEOR: 0.5930\n5. Saving file...\n   File saved: Analysis_Vi_En.csv\n----------------------------------------\n","output_type":"stream"}],"execution_count":5}]}