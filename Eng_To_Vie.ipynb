{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14095803,"sourceType":"datasetVersion","datasetId":8976326,"isSourceIdPinned":false}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets evaluate sacrebleu accelerate\n!apt install git-lfs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:54:05.495952Z","iopub.execute_input":"2025-12-13T03:54:05.496246Z","iopub.status.idle":"2025-12-13T03:55:38.134111Z","shell.execute_reply.started":"2025-12-13T03:54:05.496221Z","shell.execute_reply":"2025-12-13T03:55:38.133198Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ngit-lfs is already the newest version (3.0.2-1ubuntu0.3).\n0 upgraded, 0 newly installed, 0 to remove and 165 not upgraded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -U \"protobuf==3.20.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:38.135265Z","iopub.execute_input":"2025-12-13T03:55:38.135839Z","iopub.status.idle":"2025-12-13T03:55:42.176156Z","shell.execute_reply.started":"2025-12-13T03:55:38.135802Z","shell.execute_reply":"2025-12-13T03:55:42.175468Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf==3.20.3\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom datasets import Dataset, DatasetDict\n\nbase_path = \"/kaggle/input/vlsp-dataset\"\ntrain_en_path = os.path.join(base_path, \"train.en.txt\")\ntrain_vi_path = os.path.join(base_path, \"train.vi.txt\")\ntest_en_path = os.path.join(base_path, \"public_test.en.txt\")\ntest_vi_path = os.path.join(base_path, \"public_test.vi.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:42.177919Z","iopub.execute_input":"2025-12-13T03:55:42.178626Z","iopub.status.idle":"2025-12-13T03:55:48.545474Z","shell.execute_reply.started":"2025-12-13T03:55:42.178588Z","shell.execute_reply":"2025-12-13T03:55:48.544905Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def read_text_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        lines = f.read().splitlines()\n    return lines","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:48.546213Z","iopub.execute_input":"2025-12-13T03:55:48.546650Z","iopub.status.idle":"2025-12-13T03:55:48.550797Z","shell.execute_reply.started":"2025-12-13T03:55:48.546626Z","shell.execute_reply":"2025-12-13T03:55:48.550182Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(\"Đang đọc dữ liệu...\")\ntrain_en = read_text_file(train_en_path)\ntrain_vi = read_text_file(train_vi_path)\nval_en = read_text_file(test_en_path)\nval_vi = read_text_file(test_vi_path)\n\nprint(f\"Số câu Train En: {len(train_en)}\")\nprint(f\"Số câu Train Vi: {len(train_vi)}\")\nassert len(train_en) == len(train_vi), \"Lỗi: Số dòng file Anh và Việt không khớp nhau!\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:48.554119Z","iopub.execute_input":"2025-12-13T03:55:48.554428Z","iopub.status.idle":"2025-12-13T03:55:52.269125Z","shell.execute_reply.started":"2025-12-13T03:55:48.554411Z","shell.execute_reply":"2025-12-13T03:55:52.268444Z"}},"outputs":[{"name":"stdout","text":"Đang đọc dữ liệu...\nSố câu Train En: 500000\nSố câu Train Vi: 500000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_dataset = Dataset.from_dict({\"en\": train_en, \"vi\": train_vi})\nval_dataset = Dataset.from_dict({\"en\": val_en, \"vi\": val_vi})\n\nraw_datasets = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n})\n\nprint(\"Load dữ liệu thành công:\")\nprint(raw_datasets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:52.269888Z","iopub.execute_input":"2025-12-13T03:55:52.270165Z","iopub.status.idle":"2025-12-13T03:55:54.139304Z","shell.execute_reply.started":"2025-12-13T03:55:52.270133Z","shell.execute_reply":"2025-12-13T03:55:54.138668Z"}},"outputs":[{"name":"stdout","text":"Load dữ liệu thành công:\nDatasetDict({\n    train: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 500000\n    })\n    validation: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 3000\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"facebook/nllb-200-distilled-600M\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ndef preprocess_function(examples):\n    inputs = examples[\"en\"]\n    targets = examples[\"vi\"]\n    \n    tokenizer.src_lang = \"eng_Latn\"\n    tokenizer.tgt_lang = \"vie_Latn\"\n\n    model_inputs = tokenizer(\n        inputs,                      \n        text_target=targets,          \n        max_length=128,\n        truncation=True\n    )\n    \n    return model_inputs\n\ntokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:54.140062Z","iopub.execute_input":"2025-12-13T03:55:54.140313Z","iopub.status.idle":"2025-12-13T03:57:12.137303Z","shell.execute_reply.started":"2025-12-13T03:55:54.140285Z","shell.execute_reply":"2025-12-13T03:57:12.136529Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dbc9da347d34beeb90cb931c75a5a26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c6bc740a7d41ebbfeb6d0f7112b6e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ca5275edfc4e7ebcd81b3a321947f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d81828fd7334f90ab9fd45fd8f728ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2343f15958a549f0adfa121ebfc337f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d3e01333ae47109ece5642e9f34982"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nfrom transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:12.139168Z","iopub.execute_input":"2025-12-13T03:57:12.139397Z","iopub.status.idle":"2025-12-13T03:57:45.843385Z","shell.execute_reply.started":"2025-12-13T03:57:12.139379Z","shell.execute_reply":"2025-12-13T03:57:45.842391Z"}},"outputs":[{"name":"stderr","text":"2025-12-13 03:57:15.639902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765598236.040788      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765598236.158340      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n\nmetric = evaluate.load(\"sacrebleu\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n        \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    \n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n    \n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:45.844651Z","iopub.execute_input":"2025-12-13T03:57:45.845281Z","iopub.status.idle":"2025-12-13T03:57:59.380973Z","shell.execute_reply.started":"2025-12-13T03:57:45.845259Z","shell.execute_reply":"2025-12-13T03:57:59.380091Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33300bba84ad46a9ab80bd2b47fb69a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fa1b0092f149a4ac9e1718621a2210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4760ded0d8641579a34fa33976afa83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1eafa5e15e4b44b27948b8c6293ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b7091edec7423dbabf1a2e899383cc"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch\nimport gc\n\ngc.collect()\ntorch.cuda.empty_cache()\nprint(\"Đã dọn dẹp bộ nhớ GPU!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:59.381786Z","iopub.execute_input":"2025-12-13T03:57:59.382725Z","iopub.status.idle":"2025-12-13T03:57:59.889681Z","shell.execute_reply.started":"2025-12-13T03:57:59.382692Z","shell.execute_reply":"2025-12-13T03:57:59.888322Z"}},"outputs":[{"name":"stdout","text":"Đã dọn dẹp bộ nhớ GPU!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport torch\nimport gc\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\nfrom peft import get_peft_model, LoraConfig, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:59.892780Z","iopub.execute_input":"2025-12-13T03:57:59.893083Z","iopub.status.idle":"2025-12-13T03:58:08.906277Z","shell.execute_reply.started":"2025-12-13T03:57:59.893058Z","shell.execute_reply":"2025-12-13T03:58:08.905676Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:58:08.906904Z","iopub.execute_input":"2025-12-13T03:58:08.907119Z","iopub.status.idle":"2025-12-13T03:58:09.692443Z","shell.execute_reply.started":"2025-12-13T03:58:08.907104Z","shell.execute_reply":"2025-12-13T03:58:09.691681Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"17"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"base_path = \"/kaggle/input/vlsp-dataset\"\ndef read_text_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read().splitlines()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:58:27.454485Z","iopub.execute_input":"2025-12-13T03:58:27.455202Z","iopub.status.idle":"2025-12-13T03:58:27.458890Z","shell.execute_reply.started":"2025-12-13T03:58:27.455177Z","shell.execute_reply":"2025-12-13T03:58:27.458198Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"Đang load dữ liệu...\")\ntrain_dataset = Dataset.from_dict({\"en\": read_text_file(os.path.join(base_path, \"train.en.txt\")), \"vi\": read_text_file(os.path.join(base_path, \"train.vi.txt\"))})\nval_data_full = Dataset.from_dict({\"en\": read_text_file(os.path.join(base_path, \"public_test.en.txt\")), \"vi\": read_text_file(os.path.join(base_path, \"public_test.vi.txt\"))})\nval_dataset = val_data_full.select(range(500)) \n\nraw_datasets = DatasetDict({'train': train_dataset, 'validation': val_dataset})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:00:24.716772Z","iopub.execute_input":"2025-12-13T04:00:24.717525Z","iopub.status.idle":"2025-12-13T04:00:27.851590Z","shell.execute_reply.started":"2025-12-13T04:00:24.717500Z","shell.execute_reply":"2025-12-13T04:00:27.850779Z"}},"outputs":[{"name":"stdout","text":"Đang load dữ liệu...\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model_checkpoint = \"facebook/nllb-200-distilled-600M\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, src_lang=\"eng_Latn\", tgt_lang=\"vie_Latn\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:00:35.829181Z","iopub.execute_input":"2025-12-13T04:00:35.829455Z","iopub.status.idle":"2025-12-13T04:00:37.183702Z","shell.execute_reply.started":"2025-12-13T04:00:35.829436Z","shell.execute_reply":"2025-12-13T04:00:37.183142Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def preprocess_function(examples):\n    model_inputs = tokenizer(examples[\"en\"], text_target=examples[\"vi\"], max_length=128, truncation=True)\n    return model_inputs\n\ntokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:00:42.239544Z","iopub.execute_input":"2025-12-13T04:00:42.239817Z","iopub.status.idle":"2025-12-13T04:01:45.242032Z","shell.execute_reply.started":"2025-12-13T04:00:42.239797Z","shell.execute_reply":"2025-12-13T04:01:45.241277Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6e4b74f59744aa3b6598544735b06a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e4af69098cd41b4b2200f1f0d78514f"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"print(\"Đang load model...\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:02:44.923821Z","iopub.execute_input":"2025-12-13T04:02:44.924233Z","iopub.status.idle":"2025-12-13T04:02:48.257382Z","shell.execute_reply.started":"2025-12-13T04:02:44.924208Z","shell.execute_reply":"2025-12-13T04:02:48.256586Z"}},"outputs":[{"name":"stdout","text":"Đang load model...\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"peft_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM, \n    inference_mode=False, \n    r=16,               \n    lora_alpha=32, \n    lora_dropout=0.1,\n    target_modules=[\"q_proj\", \"v_proj\"]\n)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:02:55.255533Z","iopub.execute_input":"2025-12-13T04:02:55.256182Z","iopub.status.idle":"2025-12-13T04:02:55.365486Z","shell.execute_reply.started":"2025-12-13T04:02:55.256156Z","shell.execute_reply":"2025-12-13T04:02:55.364695Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,359,296 || all params: 617,433,088 || trainable%: 0.3821\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"args = Seq2SeqTrainingArguments(\n    output_dir=\"medical_nllb_final\",\n    eval_strategy=\"steps\",\n    eval_steps=1000,                \n    save_strategy=\"steps\",\n    save_steps=1000,                \n    learning_rate=3e-4,\n    \n    max_steps=4000,                 \n    \n    per_device_train_batch_size=4,   \n    gradient_accumulation_steps=8,  \n    gradient_checkpointing=False,    \n    \n    per_device_eval_batch_size=4,\n    weight_decay=0.01,\n    save_total_limit=2,             \n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:04:03.114893Z","iopub.execute_input":"2025-12-13T04:04:03.115627Z","iopub.status.idle":"2025-12-13T04:04:03.151421Z","shell.execute_reply.started":"2025-12-13T04:04:03.115600Z","shell.execute_reply":"2025-12-13T04:04:03.150777Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:04:10.377887Z","iopub.execute_input":"2025-12-13T04:04:10.378635Z","iopub.status.idle":"2025-12-13T04:04:11.792554Z","shell.execute_reply.started":"2025-12-13T04:04:10.378610Z","shell.execute_reply":"2025-12-13T04:04:11.791945Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/3298469325.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nNo label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(\"Bắt đầu train \")\ntrainer.train()\n\ntrainer.model.save_pretrained(\"./final_adapter\")\ntokenizer.save_pretrained(\"./final_adapter\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:06:25.699520Z","iopub.execute_input":"2025-12-13T04:06:25.699837Z"}},"outputs":[{"name":"stdout","text":"Bắt đầu train \n","output_type":"stream"},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1839' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1839/4000 3:24:38 < 4:00:43, 0.15 it/s, Epoch 0.24/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>1.847500</td>\n      <td>1.597618</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os\n\nos.makedirs(\"./export_model\", exist_ok=True)\n\n!cp -r ./final_adapter/* ./export_model/\n\n!zip -r Medical_Translation_BLEU40.zip ./export_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:37:20.691329Z","iopub.execute_input":"2025-12-12T10:37:20.691683Z","iopub.status.idle":"2025-12-12T10:37:23.167893Z","shell.execute_reply.started":"2025-12-12T10:37:20.691658Z","shell.execute_reply":"2025-12-12T10:37:23.166666Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: export_model/ (stored 0%)\n  adding: export_model/special_tokens_map.json (deflated 79%)\n  adding: export_model/sentencepiece.bpe.model","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 51%)\n  adding: export_model/README.md (deflated 66%)\n  adding: export_model/adapter_model.safetensors (deflated 7%)\n  adding: export_model/adapter_config.json (deflated 55%)\n  adding: export_model/tokenizer.json (deflated 82%)\n  adding: export_model/tokenizer_config.json (deflated 94%)\n","output_type":"stream"}],"execution_count":18}]}