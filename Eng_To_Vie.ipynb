{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14095803,"sourceType":"datasetVersion","datasetId":8976326,"isSourceIdPinned":false}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets evaluate sacrebleu accelerate\n!apt install git-lfs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:54:05.495952Z","iopub.execute_input":"2025-12-13T03:54:05.496246Z","iopub.status.idle":"2025-12-13T03:55:38.134111Z","shell.execute_reply.started":"2025-12-13T03:54:05.496221Z","shell.execute_reply":"2025-12-13T03:55:38.133198Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ngit-lfs is already the newest version (3.0.2-1ubuntu0.3).\n0 upgraded, 0 newly installed, 0 to remove and 165 not upgraded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -U \"protobuf==3.20.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:38.135265Z","iopub.execute_input":"2025-12-13T03:55:38.135839Z","iopub.status.idle":"2025-12-13T03:55:42.176156Z","shell.execute_reply.started":"2025-12-13T03:55:38.135802Z","shell.execute_reply":"2025-12-13T03:55:42.175468Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf==3.20.3\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom datasets import Dataset, DatasetDict\n\nbase_path = \"/kaggle/input/vlsp-dataset\"\ntrain_en_path = os.path.join(base_path, \"train.en.txt\")\ntrain_vi_path = os.path.join(base_path, \"train.vi.txt\")\ntest_en_path = os.path.join(base_path, \"public_test.en.txt\")\ntest_vi_path = os.path.join(base_path, \"public_test.vi.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:42.177919Z","iopub.execute_input":"2025-12-13T03:55:42.178626Z","iopub.status.idle":"2025-12-13T03:55:48.545474Z","shell.execute_reply.started":"2025-12-13T03:55:42.178588Z","shell.execute_reply":"2025-12-13T03:55:48.544905Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def read_text_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        lines = f.read().splitlines()\n    return lines","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:48.546213Z","iopub.execute_input":"2025-12-13T03:55:48.546650Z","iopub.status.idle":"2025-12-13T03:55:48.550797Z","shell.execute_reply.started":"2025-12-13T03:55:48.546626Z","shell.execute_reply":"2025-12-13T03:55:48.550182Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(\"Äang Ä‘á»c dá»¯ liá»‡u...\")\ntrain_en = read_text_file(train_en_path)\ntrain_vi = read_text_file(train_vi_path)\nval_en = read_text_file(test_en_path)\nval_vi = read_text_file(test_vi_path)\n\nprint(f\"Sá»‘ cÃ¢u Train En: {len(train_en)}\")\nprint(f\"Sá»‘ cÃ¢u Train Vi: {len(train_vi)}\")\nassert len(train_en) == len(train_vi), \"Lá»—i: Sá»‘ dÃ²ng file Anh vÃ  Viá»‡t khÃ´ng khá»›p nhau!\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:48.554119Z","iopub.execute_input":"2025-12-13T03:55:48.554428Z","iopub.status.idle":"2025-12-13T03:55:52.269125Z","shell.execute_reply.started":"2025-12-13T03:55:48.554411Z","shell.execute_reply":"2025-12-13T03:55:52.268444Z"}},"outputs":[{"name":"stdout","text":"Äang Ä‘á»c dá»¯ liá»‡u...\nSá»‘ cÃ¢u Train En: 500000\nSá»‘ cÃ¢u Train Vi: 500000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_dataset = Dataset.from_dict({\"en\": train_en, \"vi\": train_vi})\nval_dataset = Dataset.from_dict({\"en\": val_en, \"vi\": val_vi})\n\nraw_datasets = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n})\n\nprint(\"Load dá»¯ liá»‡u thÃ nh cÃ´ng:\")\nprint(raw_datasets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:52.269888Z","iopub.execute_input":"2025-12-13T03:55:52.270165Z","iopub.status.idle":"2025-12-13T03:55:54.139304Z","shell.execute_reply.started":"2025-12-13T03:55:52.270133Z","shell.execute_reply":"2025-12-13T03:55:54.138668Z"}},"outputs":[{"name":"stdout","text":"Load dá»¯ liá»‡u thÃ nh cÃ´ng:\nDatasetDict({\n    train: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 500000\n    })\n    validation: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 3000\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"facebook/nllb-200-distilled-600M\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ndef preprocess_function(examples):\n    inputs = examples[\"en\"]\n    targets = examples[\"vi\"]\n    \n    tokenizer.src_lang = \"eng_Latn\"\n    tokenizer.tgt_lang = \"vie_Latn\"\n\n    model_inputs = tokenizer(\n        inputs,                      \n        text_target=targets,          \n        max_length=128,\n        truncation=True\n    )\n    \n    return model_inputs\n\ntokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:55:54.140062Z","iopub.execute_input":"2025-12-13T03:55:54.140313Z","iopub.status.idle":"2025-12-13T03:57:12.137303Z","shell.execute_reply.started":"2025-12-13T03:55:54.140285Z","shell.execute_reply":"2025-12-13T03:57:12.136529Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dbc9da347d34beeb90cb931c75a5a26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c6bc740a7d41ebbfeb6d0f7112b6e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ca5275edfc4e7ebcd81b3a321947f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d81828fd7334f90ab9fd45fd8f728ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2343f15958a549f0adfa121ebfc337f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d3e01333ae47109ece5642e9f34982"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nfrom transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:12.139168Z","iopub.execute_input":"2025-12-13T03:57:12.139397Z","iopub.status.idle":"2025-12-13T03:57:45.843385Z","shell.execute_reply.started":"2025-12-13T03:57:12.139379Z","shell.execute_reply":"2025-12-13T03:57:45.842391Z"}},"outputs":[{"name":"stderr","text":"2025-12-13 03:57:15.639902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765598236.040788      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765598236.158340      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n\nmetric = evaluate.load(\"sacrebleu\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n        \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    \n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n    \n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:45.844651Z","iopub.execute_input":"2025-12-13T03:57:45.845281Z","iopub.status.idle":"2025-12-13T03:57:59.380973Z","shell.execute_reply.started":"2025-12-13T03:57:45.845259Z","shell.execute_reply":"2025-12-13T03:57:59.380091Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33300bba84ad46a9ab80bd2b47fb69a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fa1b0092f149a4ac9e1718621a2210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4760ded0d8641579a34fa33976afa83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1eafa5e15e4b44b27948b8c6293ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b7091edec7423dbabf1a2e899383cc"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch\nimport gc\n\ngc.collect()\ntorch.cuda.empty_cache()\nprint(\"ÄÃ£ dá»n dáº¹p bá»™ nhá»› GPU!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:59.381786Z","iopub.execute_input":"2025-12-13T03:57:59.382725Z","iopub.status.idle":"2025-12-13T03:57:59.889681Z","shell.execute_reply.started":"2025-12-13T03:57:59.382692Z","shell.execute_reply":"2025-12-13T03:57:59.888322Z"}},"outputs":[{"name":"stdout","text":"ÄÃ£ dá»n dáº¹p bá»™ nhá»› GPU!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport torch\nimport gc\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\nfrom peft import get_peft_model, LoraConfig, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:57:59.892780Z","iopub.execute_input":"2025-12-13T03:57:59.893083Z","iopub.status.idle":"2025-12-13T03:58:08.906277Z","shell.execute_reply.started":"2025-12-13T03:57:59.893058Z","shell.execute_reply":"2025-12-13T03:58:08.905676Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:58:08.906904Z","iopub.execute_input":"2025-12-13T03:58:08.907119Z","iopub.status.idle":"2025-12-13T03:58:09.692443Z","shell.execute_reply.started":"2025-12-13T03:58:08.907104Z","shell.execute_reply":"2025-12-13T03:58:09.691681Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"17"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"base_path = \"/kaggle/input/vlsp-dataset\"\ndef read_text_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read().splitlines()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T03:58:27.454485Z","iopub.execute_input":"2025-12-13T03:58:27.455202Z","iopub.status.idle":"2025-12-13T03:58:27.458890Z","shell.execute_reply.started":"2025-12-13T03:58:27.455177Z","shell.execute_reply":"2025-12-13T03:58:27.458198Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"Äang load dá»¯ liá»‡u...\")\ntrain_dataset = Dataset.from_dict({\"en\": read_text_file(os.path.join(base_path, \"train.en.txt\")), \"vi\": read_text_file(os.path.join(base_path, \"train.vi.txt\"))})\nval_data_full = Dataset.from_dict({\"en\": read_text_file(os.path.join(base_path, \"public_test.en.txt\")), \"vi\": read_text_file(os.path.join(base_path, \"public_test.vi.txt\"))})\nval_dataset = val_data_full.select(range(500)) \n\nraw_datasets = DatasetDict({'train': train_dataset, 'validation': val_dataset})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:00:24.716772Z","iopub.execute_input":"2025-12-13T04:00:24.717525Z","iopub.status.idle":"2025-12-13T04:00:27.851590Z","shell.execute_reply.started":"2025-12-13T04:00:24.717500Z","shell.execute_reply":"2025-12-13T04:00:27.850779Z"}},"outputs":[{"name":"stdout","text":"Äang load dá»¯ liá»‡u...\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model_checkpoint = \"facebook/nllb-200-distilled-600M\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, src_lang=\"eng_Latn\", tgt_lang=\"vie_Latn\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:00:35.829181Z","iopub.execute_input":"2025-12-13T04:00:35.829455Z","iopub.status.idle":"2025-12-13T04:00:37.183702Z","shell.execute_reply.started":"2025-12-13T04:00:35.829436Z","shell.execute_reply":"2025-12-13T04:00:37.183142Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def preprocess_function(examples):\n    model_inputs = tokenizer(examples[\"en\"], text_target=examples[\"vi\"], max_length=128, truncation=True)\n    return model_inputs\n\ntokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:00:42.239544Z","iopub.execute_input":"2025-12-13T04:00:42.239817Z","iopub.status.idle":"2025-12-13T04:01:45.242032Z","shell.execute_reply.started":"2025-12-13T04:00:42.239797Z","shell.execute_reply":"2025-12-13T04:01:45.241277Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6e4b74f59744aa3b6598544735b06a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e4af69098cd41b4b2200f1f0d78514f"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"print(\"Äang load model...\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:02:44.923821Z","iopub.execute_input":"2025-12-13T04:02:44.924233Z","iopub.status.idle":"2025-12-13T04:02:48.257382Z","shell.execute_reply.started":"2025-12-13T04:02:44.924208Z","shell.execute_reply":"2025-12-13T04:02:48.256586Z"}},"outputs":[{"name":"stdout","text":"Äang load model...\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"peft_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM, \n    inference_mode=False, \n    r=16,               \n    lora_alpha=32, \n    lora_dropout=0.1,\n    target_modules=[\"q_proj\", \"v_proj\"]\n)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:02:55.255533Z","iopub.execute_input":"2025-12-13T04:02:55.256182Z","iopub.status.idle":"2025-12-13T04:02:55.365486Z","shell.execute_reply.started":"2025-12-13T04:02:55.256156Z","shell.execute_reply":"2025-12-13T04:02:55.364695Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,359,296 || all params: 617,433,088 || trainable%: 0.3821\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"args = Seq2SeqTrainingArguments(\n    output_dir=\"medical_nllb_final\",\n    eval_strategy=\"steps\",\n    eval_steps=1000,                \n    save_strategy=\"steps\",\n    save_steps=1000,                \n    learning_rate=3e-4,\n    \n    max_steps=4000,                 \n    \n    per_device_train_batch_size=4,   \n    gradient_accumulation_steps=8,  \n    gradient_checkpointing=False,    \n    \n    per_device_eval_batch_size=4,\n    weight_decay=0.01,\n    save_total_limit=2,             \n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:04:03.114893Z","iopub.execute_input":"2025-12-13T04:04:03.115627Z","iopub.status.idle":"2025-12-13T04:04:03.151421Z","shell.execute_reply.started":"2025-12-13T04:04:03.115600Z","shell.execute_reply":"2025-12-13T04:04:03.150777Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:04:10.377887Z","iopub.execute_input":"2025-12-13T04:04:10.378635Z","iopub.status.idle":"2025-12-13T04:04:11.792554Z","shell.execute_reply.started":"2025-12-13T04:04:10.378610Z","shell.execute_reply":"2025-12-13T04:04:11.791945Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/3298469325.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nNo label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(\"Báº¯t Ä‘áº§u train \")\ntrainer.train()\n\ntrainer.model.save_pretrained(\"./final_adapter\")\ntokenizer.save_pretrained(\"./final_adapter\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:06:25.699520Z","iopub.execute_input":"2025-12-13T04:06:25.699837Z"}},"outputs":[{"name":"stdout","text":"Báº¯t Ä‘áº§u train \n","output_type":"stream"},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1839' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1839/4000 3:24:38 < 4:00:43, 0.15 it/s, Epoch 0.24/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>1.847500</td>\n      <td>1.597618</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom peft import PeftModel\n\nbase_model_id = \"facebook/nllb-200-distilled-600M\"\nadapter_path = \"./final_adapter\"  \n\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, src_lang=\"eng_Latn\")\n\nprint(\"Äang load Base Model...\")\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_id)\n\nprint(\"Äang gáº¯n Adapter Y táº¿...\")\nmodel = PeftModel.from_pretrained(base_model, adapter_path)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\nmodel.eval() \nprint(f\"Load model thÃ nh cÃ´ng trÃªn thiáº¿t bá»‹: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T17:14:03.486595Z","iopub.execute_input":"2025-12-13T17:14:03.487254Z","iopub.status.idle":"2025-12-13T17:15:10.731594Z","shell.execute_reply.started":"2025-12-13T17:14:03.487230Z","shell.execute_reply":"2025-12-13T17:15:10.723555Z"}},"outputs":[{"name":"stderr","text":"2025-12-13 17:14:23.914763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765646064.336885      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765646064.422446      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91082d46821f4e71b1f9a1a05849ce49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce2d0f5a046447549dfca6c980d5a3de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5190bf5247b74ed0afca5aeba81a6575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4616337ecdad4ba898a688d502c9e2d0"}},"metadata":{}},{"name":"stdout","text":"Äang load Base Model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99c7d7728d7b473c9cf02a72b97ef730"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20d80a44e1924e8a8430dbff503b4325"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"331b50caf05e4ce4b211be7b444b638a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14237fb0c5d743138eb0ec1f012a7807"}},"metadata":{}},{"name":"stdout","text":"Äang gáº¯n Adapter Y táº¿...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/config.py\u001b[0m in \u001b[0;36m_get_peft_type\u001b[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 config_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mREPO_ID_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34m\"Repo id must use alphanumeric chars, '-', '_' or '.'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: './final_adapter'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2818101584.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Äang gáº¯n Adapter Y táº¿...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, key_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             config = PEFT_TYPE_TO_CONFIG_MAPPING[\n\u001b[0;32m--> 440\u001b[0;31m                 PeftConfig._get_peft_type(\n\u001b[0m\u001b[1;32m    441\u001b[0m                     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subfolder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/config.py\u001b[0m in \u001b[0;36m_get_peft_type\u001b[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 )\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can't find '{CONFIG_NAME}' at '{model_id}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mloaded_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Can't find 'adapter_config.json' at './final_adapter'"],"ename":"ValueError","evalue":"Can't find 'adapter_config.json' at './final_adapter'","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"def medical_translate(text):\n    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n    \n    target_lang_id = tokenizer.convert_tokens_to_ids(\"vie_Latn\")\n\n    with torch.no_grad():\n        translated_tokens = model.generate(\n            **inputs,\n            forced_bos_token_id=target_lang_id, \n            max_length=128,\n            num_beams=5,\n            early_stopping=True\n        )\n    \n    result = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T17:12:54.976859Z","iopub.execute_input":"2025-12-13T17:12:54.977125Z","iopub.status.idle":"2025-12-13T17:12:54.985362Z","shell.execute_reply.started":"2025-12-13T17:12:54.977106Z","shell.execute_reply":"2025-12-13T17:12:54.984696Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"test_sentences = [\n    \"I love you\",\n    \"Please prescribe 500mg of Paracetamol to be taken twice daily after meals.\",\n    \"Common symptoms of type 2 diabetes include increased thirst and frequent urination.\",\n    \"The MRI scan revealed a small tumor in the left hemisphere of the brain.\",\n    \"Wash your hands thoroughly to prevent the spread of bacterial infection.\"\n]\n\nprint(\"-\" * 50)\nprint(\"Káº¾T QUáº¢ Dá»ŠCH Y Táº¾ (ANH -> VIá»†T)\")\nprint(\"-\" * 50)\n\nfor en_text in test_sentences:\n    vi_text = medical_translate(en_text)\n    print(f\"ğŸ‡¬ğŸ‡§ En: {en_text}\")\n    print(f\"ğŸ‡»ğŸ‡³ Vi: {vi_text}\")\n    print(\"-\" * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T17:13:59.190006Z","iopub.execute_input":"2025-12-13T17:13:59.190799Z","iopub.status.idle":"2025-12-13T17:13:59.259045Z","shell.execute_reply.started":"2025-12-13T17:13:59.190774Z","shell.execute_reply":"2025-12-13T17:13:59.258034Z"}},"outputs":[{"name":"stdout","text":"--------------------------------------------------\nKáº¾T QUáº¢ Dá»ŠCH Y Táº¾ (ANH -> VIá»†T)\n--------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2993599471.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0men_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mvi_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedical_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ğŸ‡¬ğŸ‡§ En: {en_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ğŸ‡»ğŸ‡³ Vi: {vi_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/3936592339.py\u001b[0m in \u001b[0;36mmedical_translate\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmedical_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_lang_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vie_Latn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"],"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:28:03.119213Z","iopub.execute_input":"2025-12-12T10:28:03.119562Z","iopub.status.idle":"2025-12-12T10:28:03.478020Z","shell.execute_reply.started":"2025-12-12T10:28:03.119502Z","shell.execute_reply":"2025-12-12T10:28:03.477325Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"metric = evaluate.load(\"sacrebleu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:29:13.200591Z","iopub.execute_input":"2025-12-12T10:29:13.201350Z","iopub.status.idle":"2025-12-12T10:29:14.011605Z","shell.execute_reply.started":"2025-12-12T10:29:13.201321Z","shell.execute_reply":"2025-12-12T10:29:14.010746Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14f3c701c9ce420f9d4bdf234a3e9a6f"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def generate_translations(model, tokenizer, dataset, batch_size=8, device=\"cuda\"):\n    model.eval()\n    inputs = dataset[\"en\"] \n    references = dataset[\"vi\"]\n    \n    predictions = []\n    \n    print(f\"Äang Ä‘Ã¡nh giÃ¡ trÃªn {len(inputs)} cÃ¢u...\")\n    for i in tqdm(range(0, len(inputs), batch_size)):\n        batch_inputs = inputs[i : i + batch_size]\n        \n        input_tokens = tokenizer(batch_inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n        \n        with torch.no_grad():\n            generated_tokens = model.generate(\n                **input_tokens,\n                forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"vie_Latn\"),\n                max_length=128,\n                num_beams=3, \n                early_stopping=True\n            )\n            \n        batch_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n        predictions.extend(batch_preds)\n        \n    return predictions, references\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:29:21.751346Z","iopub.execute_input":"2025-12-12T10:29:21.752151Z","iopub.status.idle":"2025-12-12T10:29:21.758949Z","shell.execute_reply.started":"2025-12-12T10:29:21.752119Z","shell.execute_reply":"2025-12-12T10:29:21.758020Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"preds, refs = generate_translations(model, tokenizer, val_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:29:23.592130Z","iopub.execute_input":"2025-12-12T10:29:23.592687Z","iopub.status.idle":"2025-12-12T10:31:49.246054Z","shell.execute_reply.started":"2025-12-12T10:29:23.592662Z","shell.execute_reply":"2025-12-12T10:31:49.245289Z"}},"outputs":[{"name":"stdout","text":"Äang Ä‘Ã¡nh giÃ¡ trÃªn 500 cÃ¢u...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [02:25<00:00,  2.31s/it]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"formatted_refs = [[r] for r in refs]\n\nresults = metric.compute(predictions=preds, references=formatted_refs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:32:03.908598Z","iopub.execute_input":"2025-12-12T10:32:03.908905Z","iopub.status.idle":"2025-12-12T10:32:04.089076Z","shell.execute_reply.started":"2025-12-12T10:32:03.908882Z","shell.execute_reply":"2025-12-12T10:32:04.088163Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*30)\nprint(f\"Káº¾T QUáº¢ ÄÃNH GIÃ:\")\nprint(f\"BLEU Score: {results['score']:.2f}\")\nprint(\"=\"*30)\n\nprint(\"\\nSo sÃ¡nh thá»±c táº¿:\")\nfor i in range(5):\n    print(f\"Gá»‘c (En): {val_dataset['en'][i]}\")\n    print(f\"MÃ¡y dá»‹ch: {preds[i]}\")\n    print(f\"ÄÃ¡p Ã¡n  : {refs[i]}\")\n    print(\"-\" * 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:32:06.090326Z","iopub.execute_input":"2025-12-12T10:32:06.090668Z","iopub.status.idle":"2025-12-12T10:32:06.100340Z","shell.execute_reply.started":"2025-12-12T10:32:06.090641Z","shell.execute_reply":"2025-12-12T10:32:06.099331Z"}},"outputs":[{"name":"stdout","text":"\n==============================\nKáº¾T QUáº¢ ÄÃNH GIÃ:\nBLEU Score: 40.46\n==============================\n\nSo sÃ¡nh thá»±c táº¿:\nGá»‘c (En): Knowledge, practices in public health service utilization among health insurance cardâ€™s holders and influencing factors in Vientiane, Lao\nMÃ¡y dá»‹ch: Kiáº¿n thá»©c, thá»±c hÃ nh sá»­ dá»¥ng dá»‹ch vá»¥ y táº¿ cÃ´ng cá»™ng cá»§a ngÆ°á»i cÃ³ tháº» báº£o hiá»ƒm y táº¿ vÃ  cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng táº¡i Viá»‡t Nam, LÃ o\nÄÃ¡p Ã¡n  : Thá»±c tráº¡ng kiáº¿n thá»©c vÃ  thá»±c hÃ nh cá»§a ngÆ°á»i cÃ³ tháº» báº£o hiá»ƒm y táº¿ trong sá»­ dá»¥ng dá»‹ch vá»¥ khÃ¡m chá»¯a bá»‡nh á»Ÿ cÃ¡c cÆ¡ sá»Ÿ y táº¿ cÃ´ng vÃ  má»™t sá»‘ yáº¿u tá»‘ áº£nh hÆ°á»Ÿng táº¡i tá»‰nh ViÃªng ChÄƒn, CHDCND LÃ o, nÄƒm 2017\n--------------------\nGá»‘c (En): Describe knowledge, practices in public health service utilization among health insurance card's holders and influencing factors in Vientiane, Lao PDR, 2017.\nMÃ¡y dá»‹ch: MÃ´ táº£ kiáº¿n thá»©c, thá»±c hÃ nh trong viá»‡c sá»­ dá»¥ng dá»‹ch vá»¥ y táº¿ cÃ´ng cá»™ng cá»§a ngÆ°á»i cÃ³ tháº» báº£o hiá»ƒm y táº¿ vÃ  cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng táº¡i Viá»‡t Nam, LÃ o nÄƒm 2017.\nÄÃ¡p Ã¡n  : MÃ´ táº£ thá»±c tráº¡ng kiáº¿n thá»©c, thá»±c hÃ nh cá»§a ngÆ°á»i cÃ³ tháº» báº£o hiá»ƒm y táº¿ trong sá»­ dá»¥ng dá»‹ch vá»¥ khÃ¡m chá»¯a bá»‡nh á»Ÿ cÃ¡c cÆ¡ sá»Ÿ y táº¿ cÃ´ng vÃ  má»™t sá»‘ yáº¿u tá»‘ liÃªn quan táº¡i tá»‰nh ViÃªng ChÄƒn, Cá»™ng hoÃ  DÃ¢n chá»§ NhÃ¢n dÃ¢n LÃ o nÄƒm 2017.\n--------------------\nGá»‘c (En): Methodology: A cross sectional study was used among 928 adult health insurance card's holders in Phone Hong and Keo Oudom districts, Vientiane province.\nMÃ¡y dá»‹ch: PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u: NghiÃªn cá»©u cáº¯t ngang Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn 928 ngÆ°á»i cÃ³ tháº» báº£o hiá»ƒm sá»©c khoáº» ngÆ°á»i lá»›n táº¡i cÃ¡c huyá»‡n Phone Hong vÃ  Keo Oudom, tá»‰nh ViÃªn Tiá»n.\nÄÃ¡p Ã¡n  : PhÆ°Æ¡ng phÃ¡p: Thiáº¿t káº¿ nghiÃªn mÃ´ táº£ cáº¯t ngang Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn 928 ngÆ°á»i trÆ°á»Ÿng thÃ nh cÃ³ tháº» báº£o hiá»ƒm y táº¿ táº¡i 2 huyá»‡n Phone Hong vÃ  Keo Oudom, tá»‰nh ViÃªng ChÄƒn.\n--------------------\nGá»‘c (En): Results: Percentage of card's holders who knew the finance-free utilization of the first registered public health services was 44.5% and being provided health insurance information was 34.8%.\nMÃ¡y dá»‹ch: Káº¿t quáº£: Tá»· lá»‡ ngÆ°á»i cÃ³ tháº» biáº¿t sá»­ dá»¥ng miá»…n phÃ­ dá»‹ch vá»¥ y táº¿ cÃ´ng cá»™ng Ä‘áº§u tiÃªn Ä‘Æ°á»£c Ä‘Äƒng kÃ½ lÃ  44,5% vÃ  Ä‘Æ°á»£c cung cáº¥p thÃ´ng tin báº£o hiá»ƒm y táº¿ lÃ  34,8%.\nÄÃ¡p Ã¡n  : Káº¿t quáº£: Tá»· lá»‡ ngÆ°á»i biáº¿t Ä‘Æ°á»£c khÃ¡m chá»¯a bá»‡nh (KCB) miá»…n phÃ­ táº¡i nÆ¡i Ä‘Äƒng kÃ½ ban Ä‘áº§u chiáº¿m 44,5%, Ä‘Æ°á»£c cung cáº¥p thÃ´ng tin vá» báº£o hiá»ƒm y táº¿ (BHYT) chiáº¿m 34,8%.\n--------------------\nGá»‘c (En): Percentage of card's holders who went to the first registered public health services was 61.8%.\nMÃ¡y dá»‹ch: Tá»· lá»‡ ngÆ°á»i cÃ³ tháº» Ä‘i Ä‘áº¿n dá»‹ch vá»¥ y táº¿ cÃ´ng cá»™ng Ä‘Äƒng kÃ½ Ä‘áº§u tiÃªn lÃ  61,8%.\nÄÃ¡p Ã¡n  : Tá»· lá»‡ ngÆ°á»i cÃ³ tháº» BHYT thá»±c hÃ nh khÃ¡m chá»¯a bá»‡nh Ä‘Ãºng nÆ¡i Ä‘Äƒng kÃ½ KCB ban Ä‘áº§u chiáº¿m 61,8%.\n--------------------\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\n\nos.makedirs(\"./export_model\", exist_ok=True)\n\n!cp -r ./final_adapter/* ./export_model/\n\n!zip -r Medical_Translation_BLEU40.zip ./export_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:37:20.691329Z","iopub.execute_input":"2025-12-12T10:37:20.691683Z","iopub.status.idle":"2025-12-12T10:37:23.167893Z","shell.execute_reply.started":"2025-12-12T10:37:20.691658Z","shell.execute_reply":"2025-12-12T10:37:23.166666Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: export_model/ (stored 0%)\n  adding: export_model/special_tokens_map.json (deflated 79%)\n  adding: export_model/sentencepiece.bpe.model","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 51%)\n  adding: export_model/README.md (deflated 66%)\n  adding: export_model/adapter_model.safetensors (deflated 7%)\n  adding: export_model/adapter_config.json (deflated 55%)\n  adding: export_model/tokenizer.json (deflated 82%)\n  adding: export_model/tokenizer_config.json (deflated 94%)\n","output_type":"stream"}],"execution_count":18}]}